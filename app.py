# ============================================================
# ì²œì•ˆê³µì¥ HACCP - Supabase ìµœì¢…íŒ (ëŒ€ì‹œë³´ë“œ/ë“±ë¡/ê³„íš/ì™„ë£Œ/ë³´ê³ ì„œ/CSVì´ì „)
# - ë°ì´í„°/ì‚¬ì§„: Supabase (DB + Storage)
# - ì‚¬ì§„: ì—¬ëŸ¬ì¥ ì—…ë¡œë“œ, ìë™ ë¦¬ì‚¬ì´ì¦ˆ/ì••ì¶•, êµì²´/ì‚­ì œ ì§€ì›
# - CSV ë¦¬ìŠ¤íŠ¸ ì´ì „(ê¸°ì¡´ êµ¬ê¸€ì‹œíŠ¸ export ë“±): Supabase DBë¡œ ì£¼ì…
# - ë³´ê³ ì„œ: ì£¼ê°„/ì›”ê°„ ì„ íƒ, ê·¸ë˜í”„ + ì—‘ì…€(ì‚¬ì§„ ë§í¬ í¬í•¨) ì¶œë ¥
# ============================================================

import io
import json
import time
import uuid
import zipfile
from datetime import datetime, date
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
import altair as alt
from PIL import Image, ImageOps

# supabase python
from supabase import create_client

# -------------------------
# 0) í˜ì´ì§€ ì„¤ì •
# -------------------------
st.set_page_config(page_title="ì²œì•ˆê³µì¥ HACCP", layout="wide")
st.title("ì²œì•ˆê³µì¥ HACCP (Supabase)")

# -------------------------
# 1) Secrets ì²´í¬ + Supabase ì—°ê²°
# -------------------------
REQUIRED_SECRETS = ["SUPABASE_URL", "SUPABASE_ANON_KEY", "SUPABASE_SERVICE_KEY", "SUPABASE_BUCKET"]

missing = [k for k in REQUIRED_SECRETS if k not in st.secrets]
if missing:
    st.error(f"ğŸš¨ Secrets ëˆ„ë½: {', '.join(missing)}")
    st.info(
        "Streamlit Cloud â†’ Settings â†’ Secrets ì— ì•„ë˜ í˜•íƒœë¡œ ë„£ìœ¼ì„¸ìš”:\n\n"
        'SUPABASE_URL = "https://xxxx.supabase.co"\n'
        'SUPABASE_ANON_KEY = "..."  \n'
        'SUPABASE_SERVICE_KEY = "..."  \n'
        'SUPABASE_BUCKET = "haccp-photos"\n'
    )
    st.stop()

SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_ANON_KEY = st.secrets["SUPABASE_ANON_KEY"]
SUPABASE_SERVICE_KEY = st.secrets["SUPABASE_SERVICE_KEY"]
SUPABASE_BUCKET = st.secrets["SUPABASE_BUCKET"]

@st.cache_resource
def get_clients():
    # anon: ì½ê¸°(ëŒ€ì‹œë³´ë“œ ë“±)
    sb_anon = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    # service: ì“°ê¸°/ì—…ë°ì´íŠ¸/ì‚­ì œ/CSVì´ì „
    sb_srv = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
    return sb_anon, sb_srv

sb, sb_admin = get_clients()

# -------------------------
# 2) ìœ í‹¸ í•¨ìˆ˜
# -------------------------
def _norm_str(x: Any) -> str:
    s = "" if x is None else str(x)
    s = s.strip()
    return "" if s.lower() == "nan" else s

def _parse_date_any(x: Any) -> Optional[str]:
    s = _norm_str(x)
    if not s:
        return None
    s = s.replace(".", "-").replace("/", "-")
    try:
        d = pd.to_datetime(s, errors="coerce")
        if pd.isna(d):
            return None
        return d.date().strftime("%Y-%m-%d")
    except Exception:
        return None

def _map_status(s: Any) -> str:
    s = _norm_str(s)
    if s in ["ì§„í–‰ì¤‘", "ê³„íšìˆ˜ë¦½", "ì™„ë£Œ"]:
        return s
    if "ì™„ë£Œ" in s:
        return "ì™„ë£Œ"
    if "ê³„íš" in s:
        return "ê³„íšìˆ˜ë¦½"
    return "ì§„í–‰ì¤‘"

def _now_ts() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def compress_images(files: List[Any], max_size: int = 1280, quality: int = 70) -> List[Tuple[str, io.BytesIO]]:
    """
    Streamlit UploadedFile ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ:
    - íšŒì „ ë³´ì •(exif)
    - RGB ë³€í™˜
    - ìµœëŒ€ ë³€ 1280 ë¦¬ì‚¬ì´ì¦ˆ
    - JPEG quality 70 ì••ì¶•
    return: (íŒŒì¼ëª…, BytesIO) ë¦¬ìŠ¤íŠ¸
    """
    out = []
    for f in files:
        try:
            img = Image.open(f)
            img = ImageOps.exif_transpose(img)
            img = img.convert("RGB")
            img.thumbnail((max_size, max_size))
            buf = io.BytesIO()
            img.save(buf, format="JPEG", quality=quality, optimize=True)
            buf.seek(0)
            name = f"{uuid.uuid4().hex}_{_norm_str(getattr(f, 'name', 'photo.jpg')).replace(' ', '_')}"
            if not name.lower().endswith(".jpg") and not name.lower().endswith(".jpeg"):
                name += ".jpg"
            out.append((name, buf))
        except Exception:
            # ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œë¼ë„ ì˜¬ë¦¬ê¸°
            try:
                buf = io.BytesIO(f.read())
                buf.seek(0)
                name = f"{uuid.uuid4().hex}_{_norm_str(getattr(f, 'name', 'photo.bin'))}"
                out.append((name, buf))
            except Exception:
                continue
    return out

def storage_public_url(path: str) -> str:
    # public bucket ê¸°ì¤€. ë§Œì•½ privateì´ë©´ signed url ë¡œì§ í•„ìš”.
    return f"{SUPABASE_URL}/storage/v1/object/public/{SUPABASE_BUCKET}/{path}"

def upload_photos_to_storage(files: List[Any], folder: str) -> List[str]:
    """
    ì—¬ëŸ¬ì¥ ì—…ë¡œë“œ â†’ Storage ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    if not files:
        return []
    compressed = compress_images(files)
    saved_paths = []
    for name, buf in compressed:
        storage_path = f"{folder}/{name}"
        try:
            sb_admin.storage.from_(SUPABASE_BUCKET).upload(
                path=storage_path,
                file=buf.getvalue(),
                file_options={"content-type": "image/jpeg", "upsert": "true"},
            )
            saved_paths.append(storage_path)
        except Exception as e:
            st.warning(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {name} / {e}")
    return saved_paths

def delete_photos(paths: List[str]) -> None:
    if not paths:
        return
    try:
        sb_admin.storage.from_(SUPABASE_BUCKET).remove(paths)
    except Exception as e:
        st.warning(f"ì‚­ì œ ì‹¤íŒ¨: {e}")

def fetch_tasks(limit: int = 5000) -> pd.DataFrame:
    """
    haccp_tasks í…Œì´ë¸” ì „ì²´ë¥¼ ì½ì–´ DataFrameìœ¼ë¡œ
    """
    try:
        res = sb.table("haccp_tasks").select("*").limit(limit).execute()
        data = res.data or []
        df = pd.DataFrame(data)
        if df.empty:
            return df
        # ë‚ ì§œ ì»¬ëŸ¼ íŒŒì‹±
        for col in ["issue_date", "plan_due_date", "action_date", "created_at", "updated_at"]:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors="coerce")
        # ì£¼/ì›”/ì—° íŒŒìƒ
        if "issue_date" in df.columns:
            df["Year"] = df["issue_date"].dt.year
            df["Month"] = df["issue_date"].dt.month
            df["Week"] = df["issue_date"].dt.isocalendar().week.astype("Int64")
        return df
    except Exception as e:
        st.error(f"DB ë¡œë”© ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def upsert_task_by_legacy_id(legacy_id: str, payload: Dict[str, Any]) -> None:
    # legacy_id ê¸°ì¤€ ìˆìœ¼ë©´ update, ì—†ìœ¼ë©´ insert
    exists = sb_admin.table("haccp_tasks").select("id").eq("legacy_id", legacy_id).execute().data
    if exists:
        sb_admin.table("haccp_tasks").update(payload).eq("legacy_id", legacy_id).execute()
    else:
        payload2 = dict(payload)
        payload2["legacy_id"] = legacy_id
        sb_admin.table("haccp_tasks").insert(payload2).execute()

def safe_json_list(x: Any) -> List[str]:
    if x is None:
        return []
    if isinstance(x, list):
        return [str(v) for v in x if str(v).strip()]
    # ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°(ì˜ˆ: "['a','b']")
    try:
        j = json.loads(x)
        if isinstance(j, list):
            return [str(v) for v in j if str(v).strip()]
    except Exception:
        pass
    # ê·¸ëƒ¥ ë‹¨ì¼ ë¬¸ìì—´
    s = _norm_str(x)
    return [s] if s else []

# -------------------------
# 3) ì‚¬ì´ë“œë°” ë©”ë‰´
# -------------------------
st.sidebar.markdown("## â˜ï¸ ì²œì•ˆê³µì¥ HACCP")
menu = st.sidebar.radio(
    "ë©”ë‰´",
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“ ê°œì„ ê³¼ì œë“±ë¡", "ğŸ§© ê°œì„ ê³„íšìˆ˜ë¦½", "âœ… ê°œì„ ì™„ë£Œ ì…ë ¥", "ğŸ§¾ ë³´ê³ ì„œ/ì¶œë ¥", "ğŸ“¦ ë¦¬ìŠ¤íŠ¸ë§Œ ì´ì „(CSV)"],
)
st.sidebar.divider()

# -------------------------
# 4) ë°ì´í„° ë¡œë“œ
# -------------------------
df_all = fetch_tasks()

# -------------------------
# 5) ëŒ€ì‹œë³´ë“œ
# -------------------------
if menu == "ğŸ“Š ëŒ€ì‹œë³´ë“œ":
    st.subheader("ğŸ“Š ìœ„ìƒì ê²€/ê°œì„  í˜„í™©")

    if df_all.empty:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSV ì´ì „ ë˜ëŠ” ë“±ë¡ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”)")
        st.stop()

    # ê¸°ê°„ í•„í„°
    st.sidebar.markdown("### ğŸ“… ê¸°ê°„ í•„í„°")
    years = sorted([int(y) for y in df_all["Year"].dropna().unique().tolist()])
    selected_years = st.sidebar.multiselect("ì—°ë„", years, default=years)

    dff = df_all.copy()
    if selected_years:
        dff = dff[dff["Year"].isin(selected_years)]

    months = sorted([int(m) for m in dff["Month"].dropna().unique().tolist()])
    month_options = [f"{m}ì›”" for m in months]
    selected_months_str = st.sidebar.multiselect("ì›”", month_options, default=month_options)

    if selected_months_str:
        selected_months = [int(m.replace("ì›”", "")) for m in selected_months_str]
        dff = dff[dff["Month"].isin(selected_months)]

    weeks = sorted([int(w) for w in dff["Week"].dropna().unique().tolist()])
    week_options = [f"{w}ì£¼ì°¨" for w in weeks]
    selected_weeks_str = st.sidebar.multiselect("ì£¼ì°¨(Week)", week_options, default=week_options)

    if selected_weeks_str:
        selected_weeks = [int(w.replace("ì£¼ì°¨", "")) for w in selected_weeks_str]
        dff = dff[dff["Week"].isin(selected_weeks)]

    total_count = len(dff)
    done_count = len(dff[dff["status"] == "ì™„ë£Œ"])
    rate = (done_count / total_count * 100) if total_count else 0

    m1, m2, m3 = st.columns(3)
    m1.metric("ì´ ë°œêµ´ ê±´ìˆ˜", f"{total_count}ê±´")
    m2.metric("ê°œì„  ì™„ë£Œ", f"{done_count}ê±´")
    m3.metric("ê°œì„ ìœ¨", f"{rate:.1f}%")

    st.divider()

    # ê·¸ë£¹ ê¸°ì¤€: ì—¬ëŸ¬ì›” ì„ íƒì´ë©´ Month, ì•„ë‹ˆë©´ location
    if len(selected_months_str) > 1:
        group_col = "Month"
        x_title = "ì›”"
        dff2 = dff.copy()
        dff2["Month"] = dff2["Month"].astype("Int64").astype(str) + "ì›”"
        grp = "Month"
    else:
        grp = "location"
        x_title = "ì¥ì†Œ/ì‹¤"

    chart_df = dff.groupby(grp).agg(
        ì´ë°œìƒ=("id", "count"),
        ì¡°ì¹˜ì™„ë£Œ=("status", lambda x: (x == "ì™„ë£Œ").sum()),
    ).reset_index()

    chart_df["ì§„í–‰ë¥ "] = (chart_df["ì¡°ì¹˜ì™„ë£Œ"] / chart_df["ì´ë°œìƒ"] * 100).fillna(0).round(1)
    chart_df["ë¼ë²¨"] = chart_df["ì§„í–‰ë¥ "].astype(str) + "%"

    c1, c2 = st.columns(2)
    with c1:
        st.markdown(f"**ğŸ”´ ì´ ë°œìƒ ê±´ìˆ˜ ({x_title}ë³„)**")
        chart1 = alt.Chart(chart_df).mark_bar().encode(
            x=alt.X(f"{grp}:N", axis=alt.Axis(labelAngle=0, title=None)),
            y=alt.Y("ì´ë°œìƒ:Q"),
            tooltip=[grp, "ì´ë°œìƒ"],
        )
        st.altair_chart(chart1, use_container_width=True)

    with c2:
        st.markdown("**ğŸŸ¢ ì¡°ì¹˜ ì™„ë£Œìœ¨ (%)**")
        base = alt.Chart(chart_df).encode(
            x=alt.X(f"{grp}:N", axis=alt.Axis(labelAngle=0, title=None)),
            y=alt.Y("ì§„í–‰ë¥ :Q"),
        )
        bars = base.mark_bar()
        text = base.mark_text(dy=-15).encode(text=alt.Text("ë¼ë²¨:N"))
        st.altair_chart(bars + text, use_container_width=True)

    st.divider()
    st.subheader("ğŸ“‹ ìƒì„¸ ë‚´ì—­ (ìµœê·¼ 10ê±´)")
    recent = dff.sort_values("issue_date", ascending=False).head(10)

    for _, r in recent.iterrows():
        icon = "âœ…" if r.get("status") == "ì™„ë£Œ" else "ğŸ”¥"
        dstr = r["issue_date"].strftime("%Y-%m-%d") if pd.notnull(r.get("issue_date")) else ""
        summary = _norm_str(r.get("issue_text"))[:25]
        with st.expander(f"{icon} [{_norm_str(r.get('status'))}] {dstr} | {_norm_str(r.get('location'))} - {summary}..."):
            colA, colB, colC = st.columns([1, 1, 2])

            before_paths = safe_json_list(r.get("photos_before"))
            after_paths = safe_json_list(r.get("photos_after"))

            with colA:
                st.caption("âŒ ê°œì„  ì „")
                if before_paths:
                    for p in before_paths:
                        st.image(storage_public_url(p), use_container_width=True)
                else:
                    st.caption("-")

            with colB:
                st.caption("âœ… ê°œì„  í›„")
                if after_paths:
                    for p in after_paths:
                        st.image(storage_public_url(p), use_container_width=True)
                else:
                    st.caption("-")

            with colC:
                st.markdown(f"**ë‚´ìš©:** {_norm_str(r.get('issue_text'))}")
                st.markdown(f"**ë°œê²¬ì:** {_norm_str(r.get('reporter'))}")
                st.markdown(f"**ë‹´ë‹¹ì(ê³„íš):** {_norm_str(r.get('plan_assignee'))}")
                if pd.notnull(r.get("plan_due_date")):
                    st.markdown(f"**ê°œì„  ì¼ì •:** {r['plan_due_date'].strftime('%Y-%m-%d')}")
                if _norm_str(r.get("plan_text")):
                    st.info(f"ê³„íš: {_norm_str(r.get('plan_text'))}")
                if _norm_str(r.get("action_text")):
                    st.success(f"ì¡°ì¹˜: {_norm_str(r.get('action_text'))}")
                if pd.notnull(r.get("action_date")):
                    st.markdown(f"**ì™„ë£Œì¼:** {r['action_date'].strftime('%Y-%m-%d')}")

# -------------------------
# 6) ê°œì„ ê³¼ì œë“±ë¡
# -------------------------
elif menu == "ğŸ“ ê°œì„ ê³¼ì œë“±ë¡":
    st.subheader("ğŸ“ ê°œì„ ê³¼ì œë“±ë¡ (ë°œê²¬ì/í’ˆì§ˆíŒ€)")

    locations = ["ì „ì²˜ë¦¬ì‹¤", "ì…êµ­ì‹¤", "ë°œíš¨ì‹¤", "ì œì„±ì‹¤", "ë³‘ì…/í¬ì¥ì‹¤", "ì›ë£Œì°½ê³ ", "ì œí’ˆì°½ê³ ", "ì‹¤í—˜ì‹¤", "í™”ì¥ì‹¤/íƒˆì˜ì‹¤", "ê¸°íƒ€"]

    with st.form("register_form"):
        issue_date = st.date_input("ë°œêµ´ ì¼ì", value=date.today())
        location = st.selectbox("ì¥ì†Œ", locations)
        reporter = st.text_input("ë°œê²¬ì(ë˜ëŠ” ë“±ë¡ì)")
        issue_text = st.text_area("ê°œì„  í•„ìš”ì‚¬í•­(ë‚´ìš©)")
        photos_before = st.file_uploader("ì‚¬ì§„(ê°œì„  ì „) - ì—¬ëŸ¬ ì¥ ê°€ëŠ¥", type=["jpg", "jpeg", "png", "webp"], accept_multiple_files=True)
        submitted = st.form_submit_button("ë“±ë¡ ì €ì¥")

    if submitted:
        if not _norm_str(issue_text):
            st.warning("ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            st.stop()

        task_id = uuid.uuid4().hex
        folder = f"tasks/{task_id}/before"

        with st.spinner("ì‚¬ì§„ ì—…ë¡œë“œ/ì €ì¥ ì¤‘..."):
            before_paths = upload_photos_to_storage(photos_before or [], folder=folder)

            payload = {
                "issue_date": issue_date.strftime("%Y-%m-%d"),
                "location": location,
                "issue_text": issue_text,
                "reporter": reporter,
                "status": "ì§„í–‰ì¤‘",
                "plan_assignee": "",
                "plan_due_date": None,
                "plan_text": "",
                "action_text": "",
                "action_date": None,
                "photos_before": before_paths,
                "photos_after": [],
                "updated_at": _now_ts(),
            }
            sb_admin.table("haccp_tasks").insert(payload).execute()

        st.success("âœ… ë“±ë¡ ì™„ë£Œ!")
        st.balloons()
        st.rerun()

# -------------------------
# 7) ê°œì„ ê³„íšìˆ˜ë¦½ (ê´€ë¦¬ì: ë‹´ë‹¹ì ì„ ì • + ì¼ì • + ê³„íš)
# -------------------------
elif menu == "ğŸ§© ê°œì„ ê³„íšìˆ˜ë¦½":
    st.subheader("ğŸ§© ê°œì„ ê³„íšìˆ˜ë¦½ (ê´€ë¦¬ììš©)")

    if df_all.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì§„í–‰ì¤‘ì¸ ê±´ë§Œ
    tasks = df_all[df_all["status"].isin(["ì§„í–‰ì¤‘", "ê³„íšìˆ˜ë¦½"])].copy()
    if tasks.empty:
        st.success("ğŸ‰ ê³„íšìˆ˜ë¦½í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì„ íƒ UI
    tasks = tasks.sort_values("issue_date", ascending=False)
    options = {r["id"]: f"{_norm_str(r.get('issue_text'))[:30]}... ({_norm_str(r.get('location'))})" for _, r in tasks.iterrows()}
    selected_id = st.selectbox("ê³„íš ìˆ˜ë¦½í•  í•­ëª© ì„ íƒ", options=list(options.keys()), format_func=lambda x: options[x])

    row = tasks[tasks["id"] == selected_id].iloc[0]

    st.divider()
    c1, c2 = st.columns([1, 2])
    with c1:
        st.caption("ğŸ“¸ ê°œì„  ì „")
        for p in safe_json_list(row.get("photos_before")):
            st.image(storage_public_url(p), use_container_width=True)

    with c2:
        st.markdown(f"**ë°œêµ´ì¼:** {row['issue_date'].strftime('%Y-%m-%d') if pd.notnull(row.get('issue_date')) else ''}")
        st.markdown(f"**ì¥ì†Œ:** {_norm_str(row.get('location'))}")
        st.info(_norm_str(row.get("issue_text")))

    st.divider()

    with st.form("plan_form"):
        assignee = st.text_input("ë‹´ë‹¹ì ì§€ì •", value=_norm_str(row.get("plan_assignee")))
        due = st.date_input("ê°œì„  ì¼ì •(ëª©í‘œ ì™„ë£Œì¼)", value=(row["plan_due_date"].date() if pd.notnull(row.get("plan_due_date")) else date.today()))
        plan_text = st.text_area("ê°œì„  ê³„íš(ë©”ëª¨)", value=_norm_str(row.get("plan_text")))
        ok = st.form_submit_button("ê³„íš ì €ì¥")

    if ok:
        payload = {
            "plan_assignee": assignee,
            "plan_due_date": due.strftime("%Y-%m-%d") if due else None,
            "plan_text": plan_text,
            "status": "ê³„íšìˆ˜ë¦½",
            "updated_at": _now_ts(),
        }
        sb_admin.table("haccp_tasks").update(payload).eq("id", selected_id).execute()
        st.success("âœ… ê°œì„ ê³„íš ì €ì¥ ì™„ë£Œ!")
        st.rerun()

# -------------------------
# 8) ê°œì„ ì™„ë£Œ ì…ë ¥ (ì¡°ì¹˜ ë‚´ìš© + ì™„ë£Œ ì‚¬ì§„ + ìƒíƒœ ì™„ë£Œ)
# -------------------------
elif menu == "âœ… ê°œì„ ì™„ë£Œ ì…ë ¥":
    st.subheader("âœ… ê°œì„ ì™„ë£Œ ì…ë ¥")

    if df_all.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì™„ë£Œê°€ ì•„ë‹Œ ê±´ë§Œ
    tasks = df_all[df_all["status"] != "ì™„ë£Œ"].copy()
    if tasks.empty:
        st.success("ğŸ‰ ì¡°ì¹˜í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    managers = ["ì „ì²´"] + sorted([_norm_str(x) for x in tasks["plan_assignee"].fillna("").unique().tolist() if _norm_str(x)])
    selected_manager = st.selectbox("ë‹´ë‹¹ì í•„í„°", managers)

    if selected_manager != "ì „ì²´":
        tasks = tasks[tasks["plan_assignee"] == selected_manager]

    if tasks.empty:
        st.info("í•´ë‹¹ ë‹´ë‹¹ì í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    tasks = tasks.sort_values("issue_date", ascending=False)
    options = {r["id"]: f"{_norm_str(r.get('issue_text'))[:30]}... ({_norm_str(r.get('location'))})" for _, r in tasks.iterrows()}
    selected_id = st.selectbox("ì™„ë£Œ ì²˜ë¦¬í•  í•­ëª© ì„ íƒ", options=list(options.keys()), format_func=lambda x: options[x])

    row = tasks[tasks["id"] == selected_id].iloc[0]

    st.divider()
    c1, c2 = st.columns([1, 2])
    with c1:
        st.caption("ğŸ“¸ ê°œì„  ì „")
        for p in safe_json_list(row.get("photos_before")):
            st.image(storage_public_url(p), use_container_width=True)

    with c2:
        st.markdown(f"**ì¥ì†Œ:** {_norm_str(row.get('location'))}")
        st.markdown(f"**ë‹´ë‹¹ì:** {_norm_str(row.get('plan_assignee'))}")
        st.info(_norm_str(row.get("issue_text")))

    st.divider()

    with st.form("action_form"):
        action_text = st.text_area("ì¡°ì¹˜ ë‚´ìš©", value=_norm_str(row.get("action_text")))
        action_date = st.date_input("ì™„ë£Œì¼", value=date.today())
        photos_after = st.file_uploader("ì¡°ì¹˜ í›„ ì‚¬ì§„ - ì—¬ëŸ¬ ì¥ ê°€ëŠ¥", type=["jpg", "jpeg", "png", "webp"], accept_multiple_files=True)
        ok = st.form_submit_button("ì™„ë£Œ ì €ì¥")

    if ok:
        if not _norm_str(action_text):
            st.warning("ì¡°ì¹˜ ë‚´ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            st.stop()

        folder = f"tasks/{selected_id}/after"
        with st.spinner("ì €ì¥ ì¤‘..."):
            after_paths = upload_photos_to_storage(photos_after or [], folder=folder)
            old_after = safe_json_list(row.get("photos_after"))
            merged_after = old_after + after_paths

            payload = {
                "action_text": action_text,
                "action_date": action_date.strftime("%Y-%m-%d") if action_date else None,
                "photos_after": merged_after,
                "status": "ì™„ë£Œ",
                "updated_at": _now_ts(),
            }
            sb_admin.table("haccp_tasks").update(payload).eq("id", selected_id).execute()

        st.success("âœ… ì™„ë£Œ ì €ì¥!")
        st.balloons()
        st.rerun()

    # ì‚¬ì§„ êµì²´/ì‚­ì œ (ì„ íƒëœ rowì— ëŒ€í•´)
    st.divider()
    st.markdown("### ğŸ§¹ ì‚¬ì§„ ê´€ë¦¬ (êµì²´/ì‚­ì œ)")
    st.caption("ì˜ëª» ì˜¬ë¦° ì‚¬ì§„ì´ ìˆìœ¼ë©´ ì‚­ì œí•˜ê±°ë‚˜ ìƒˆë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    before_list = safe_json_list(row.get("photos_before"))
    after_list = safe_json_list(row.get("photos_after"))

    colx, coly = st.columns(2)
    with colx:
        st.markdown("**ê°œì„  ì „ ì‚¬ì§„ ì‚­ì œ**")
        del_before = st.multiselect("ì‚­ì œí•  ì „ ì‚¬ì§„ ì„ íƒ", before_list, default=[])
        if st.button("ì „ ì‚¬ì§„ ì‚­ì œ ì‹¤í–‰"):
            if del_before:
                delete_photos(del_before)
                new_list = [p for p in before_list if p not in del_before]
                sb_admin.table("haccp_tasks").update({"photos_before": new_list, "updated_at": _now_ts()}).eq("id", selected_id).execute()
                st.success("ì „ ì‚¬ì§„ ì‚­ì œ ì™„ë£Œ")
                st.rerun()
            else:
                st.info("ì„ íƒëœ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤.")

    with coly:
        st.markdown("**ê°œì„  í›„ ì‚¬ì§„ ì‚­ì œ**")
        del_after = st.multiselect("ì‚­ì œí•  í›„ ì‚¬ì§„ ì„ íƒ", after_list, default=[])
        if st.button("í›„ ì‚¬ì§„ ì‚­ì œ ì‹¤í–‰"):
            if del_after:
                delete_photos(del_after)
                new_list = [p for p in after_list if p not in del_after]
                sb_admin.table("haccp_tasks").update({"photos_after": new_list, "updated_at": _now_ts()}).eq("id", selected_id).execute()
                st.success("í›„ ì‚¬ì§„ ì‚­ì œ ì™„ë£Œ")
                st.rerun()
            else:
                st.info("ì„ íƒëœ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("**ì‚¬ì§„ ì¶”ê°€ ì—…ë¡œë“œ(ê¸°ì¡´ì— ì´ì–´ë¶™ì„)**")
    add_before = st.file_uploader("ì „ ì‚¬ì§„ ì¶”ê°€", type=["jpg", "jpeg", "png", "webp"], accept_multiple_files=True, key="add_before")
    add_after = st.file_uploader("í›„ ì‚¬ì§„ ì¶”ê°€", type=["jpg", "jpeg", "png", "webp"], accept_multiple_files=True, key="add_after")

    col_add1, col_add2 = st.columns(2)
    with col_add1:
        if st.button("ì „ ì‚¬ì§„ ì¶”ê°€ ì €ì¥"):
            paths = upload_photos_to_storage(add_before or [], folder=f"tasks/{selected_id}/before")
            new_list = before_list + paths
            sb_admin.table("haccp_tasks").update({"photos_before": new_list, "updated_at": _now_ts()}).eq("id", selected_id).execute()
            st.success("ì „ ì‚¬ì§„ ì¶”ê°€ ì™„ë£Œ")
            st.rerun()

    with col_add2:
        if st.button("í›„ ì‚¬ì§„ ì¶”ê°€ ì €ì¥"):
            paths = upload_photos_to_storage(add_after or [], folder=f"tasks/{selected_id}/after")
            new_list = after_list + paths
            sb_admin.table("haccp_tasks").update({"photos_after": new_list, "updated_at": _now_ts()}).eq("id", selected_id).execute()
            st.success("í›„ ì‚¬ì§„ ì¶”ê°€ ì™„ë£Œ")
            st.rerun()

# -------------------------
# 9) ë³´ê³ ì„œ/ì¶œë ¥ (ì£¼ê°„/ì›”ê°„)
# -------------------------
elif menu == "ğŸ§¾ ë³´ê³ ì„œ/ì¶œë ¥":
    st.subheader("ğŸ§¾ ë³´ê³ ì„œ/ì¶œë ¥")

    if df_all.empty:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # showing only meaningful columns
    df = df_all.copy()

    report_unit = st.selectbox("ë³´ê³  ë‹¨ìœ„", ["ì£¼ê°„", "ì›”ê°„"])
    years = sorted([int(y) for y in df["Year"].dropna().unique().tolist()])
    y = st.selectbox("ì—°ë„ ì„ íƒ", years, index=len(years)-1 if years else 0)

    df = df[df["Year"] == y].copy()

    if report_unit == "ì£¼ê°„":
        weeks = sorted([int(w) for w in df["Week"].dropna().unique().tolist()])
        w = st.selectbox("ì£¼ì°¨ ì„ íƒ", weeks)
        df_r = df[df["Week"] == w].copy()
        title = f"{y}ë…„ {w}ì£¼ì°¨ ë³´ê³ ì„œ"
        period_label = f"{w}ì£¼ì°¨"
    else:
        months = sorted([int(m) for m in df["Month"].dropna().unique().tolist()])
        m = st.selectbox("ì›” ì„ íƒ", months)
        df_r = df[df["Month"] == m].copy()
        title = f"{y}ë…„ {m}ì›” ë³´ê³ ì„œ"
        period_label = f"{m}ì›”"

    st.markdown(f"## {title}")

    total = len(df_r)
    done = len(df_r[df_r["status"] == "ì™„ë£Œ"])
    st.write(f"- ì´ ë°œêµ´ê±´ìˆ˜: **{total}**")
    st.write(f"- ê°œì„ ì™„ë£Œê±´ìˆ˜: **{done}**")
    st.write(f"- ê°œì„ ìœ¨: **{(done/total*100):.1f}%**" if total else "- ê°œì„ ìœ¨: -")

    # ì „ì²´ ê·¸ë˜í”„: ìƒíƒœë³„
    status_df = df_r.groupby("status").size().reset_index(name="count")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### ìƒíƒœë³„ ê±´ìˆ˜")
        chart = alt.Chart(status_df).mark_bar().encode(
            x=alt.X("status:N", axis=alt.Axis(labelAngle=0)),
            y="count:Q",
            tooltip=["status", "count"],
        )
        st.altair_chart(chart, use_container_width=True)

    # ì¥ì†Œë³„ ê°œì„ ìœ¨
    with c2:
        st.markdown("### ì¥ì†Œë³„ ê°œì„ ìœ¨(ì™„ë£Œ ë¹„ìœ¨)")
        loc = df_r.groupby("location").agg(
            ì´ë°œìƒ=("id", "count"),
            ì™„ë£Œ=("status", lambda x: (x == "ì™„ë£Œ").sum()),
        ).reset_index()
        loc["ê°œì„ ìœ¨(%)"] = (loc["ì™„ë£Œ"] / loc["ì´ë°œìƒ"] * 100).fillna(0).round(1)

        loc_chart = alt.Chart(loc).mark_bar().encode(
            x=alt.X("location:N", axis=alt.Axis(labelAngle=0), sort="-y"),
            y=alt.Y("ê°œì„ ìœ¨(%):Q"),
            tooltip=["location", "ì´ë°œìƒ", "ì™„ë£Œ", "ê°œì„ ìœ¨(%)"],
        )
        st.altair_chart(loc_chart, use_container_width=True)

    st.divider()
    st.markdown("### ìƒì„¸ ë¦¬ìŠ¤íŠ¸")
    show_cols = ["issue_date", "location", "issue_text", "reporter", "plan_assignee", "plan_due_date", "status", "action_text", "action_date"]
    for c in show_cols:
        if c not in df_r.columns:
            df_r[c] = None
    st.dataframe(df_r[show_cols].sort_values("issue_date", ascending=False), use_container_width=True)

    st.divider()
    st.markdown("## ğŸ“¤ ì—‘ì…€ ì¶œë ¥ (ì‚¬ì§„ ë§í¬ í¬í•¨)")

    def build_excel_with_links(dfx: pd.DataFrame) -> bytes:
        dfx = dfx.copy()
        # ì‚¬ì§„ ë§í¬ ì»¬ëŸ¼ ìƒì„±(ì—¬ëŸ¬ì¥ â†’ ì¤„ë°”ê¿ˆ)
        def paths_to_links(paths):
            paths = safe_json_list(paths)
            return "\n".join([storage_public_url(p) for p in paths])

        dfx["photos_before_links"] = dfx.get("photos_before", None).apply(paths_to_links) if "photos_before" in dfx.columns else ""
        dfx["photos_after_links"] = dfx.get("photos_after", None).apply(paths_to_links) if "photos_after" in dfx.columns else ""

        cols = [
            "issue_date", "location", "issue_text", "reporter",
            "plan_assignee", "plan_due_date", "plan_text",
            "status", "action_text", "action_date",
            "photos_before_links", "photos_after_links",
        ]
        for c in cols:
            if c not in dfx.columns:
                dfx[c] = ""

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            dfx[cols].to_excel(writer, index=False, sheet_name="report")
            ws = writer.sheets["report"]
            # ë³´ê¸° ì¢‹ê²Œ í­
            ws.set_column(0, 0, 12)   # issue_date
            ws.set_column(1, 1, 14)   # location
            ws.set_column(2, 2, 50)   # issue_text
            ws.set_column(3, 3, 16)   # reporter
            ws.set_column(4, 4, 16)   # assignee
            ws.set_column(5, 5, 14)   # due
            ws.set_column(6, 6, 30)   # plan_text
            ws.set_column(7, 7, 10)   # status
            ws.set_column(8, 8, 30)   # action_text
            ws.set_column(9, 9, 14)   # action_date
            ws.set_column(10, 11, 60) # photo links
        output.seek(0)
        return output.getvalue()

    xbytes = build_excel_with_links(df_r)
    st.download_button(
        "â¬‡ï¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=xbytes,
        file_name=f"HACCP_{period_label}_report.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

# -------------------------
# 10) CSV ë¦¬ìŠ¤íŠ¸ë§Œ ì´ì „ (êµ¬ê¸€ì‹œíŠ¸ export ë“±)
# -------------------------
elif menu == "ğŸ“¦ ë¦¬ìŠ¤íŠ¸ë§Œ ì´ì „(CSV)":
    st.subheader("ğŸ“¦ ë¦¬ìŠ¤íŠ¸ë§Œ ì´ì „ (CSV â†’ Supabase DB)")
    st.info(
        "êµ¬ê¸€ì‹œíŠ¸ì—ì„œ CSVë¡œ ë½‘ì€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ DBë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n"
        "- ì‚¬ì§„ì€ CSVì—ëŠ” ì—†ìœ¼ë¯€ë¡œ ë‚˜ì¤‘ì— ë“±ë¡/ì™„ë£Œ ë©”ë‰´ì—ì„œ ì¶”ê°€ ê°€ëŠ¥\n"
        "- legacy_id(ê¸°ì¡´ ID) ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€/ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤."
    )

    csv_up = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
    overwrite = st.checkbox("ê¸°ì¡´ legacy_idê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°(ì—…ë°ì´íŠ¸)", value=False)

    if csv_up is None:
        st.stop()

    # ë¯¸ë¦¬ë³´ê¸°
    try:
        df_csv = pd.read_csv(csv_up)
        st.markdown("### ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 20í–‰)")
        st.dataframe(df_csv.head(20), use_container_width=True)
    except Exception as e:
        st.error(f"CSV ì½ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # ì‹¤í–‰
    if st.button("ğŸš€ ë¦¬ìŠ¤íŠ¸ ì´ì „ ì‹¤í–‰"):
        with st.spinner("ì´ì „ ì¤‘..."):
            # ì¬ë¡œë”© ìœ„í•´ ë‹¤ì‹œ read
            csv_up.seek(0)
            df_csv = pd.read_csv(csv_up)

            required_cols = ["ID", "ì¼ì‹œ", "ê³µì •", "ê°œì„  í•„ìš”ì‚¬í•­", "ë‹´ë‹¹ì", "ì§„í–‰ìƒíƒœ"]
            miss = [c for c in required_cols if c not in df_csv.columns]
            if miss:
                st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(miss)}")
                st.stop()

            prog = st.progress(0)
            ok = skipped = fail = 0

            for i, r in df_csv.iterrows():
                legacy_id = _norm_str(r.get("ID"))
                if not legacy_id:
                    fail += 1
                    prog.progress((i + 1) / len(df_csv))
                    continue

                try:
                    if not overwrite:
                        exists = sb_admin.table("haccp_tasks").select("id").eq("legacy_id", legacy_id).execute().data
                        if exists:
                            skipped += 1
                            prog.progress((i + 1) / len(df_csv))
                            continue

                    payload = {
                        "issue_date": _parse_date_any(r.get("ì¼ì‹œ")),
                        "location": _norm_str(r.get("ê³µì •")),
                        "issue_text": _norm_str(r.get("ê°œì„  í•„ìš”ì‚¬í•­")),
                        "reporter": _norm_str(r.get("ë°œê²¬ì")) if "ë°œê²¬ì" in df_csv.columns else "",
                        "status": _map_status(r.get("ì§„í–‰ìƒíƒœ")),
                        "plan_assignee": _norm_str(r.get("ë‹´ë‹¹ì")),
                        "plan_due_date": _parse_date_any(r.get("ê°œì„ ê³„íš(ì¼ì •)")) if "ê°œì„ ê³„íš(ì¼ì •)" in df_csv.columns else None,
                        "plan_text": "",
                        "action_text": _norm_str(r.get("ê°œì„ ë‚´ìš©")) if "ê°œì„ ë‚´ìš©" in df_csv.columns else "",
                        "action_date": _parse_date_any(r.get("ê°œì„ ì™„ë£Œì¼")) if "ê°œì„ ì™„ë£Œì¼" in df_csv.columns else None,
                        "photos_before": [],
                        "photos_after": [],
                        "updated_at": _now_ts(),
                    }

                    upsert_task_by_legacy_id(legacy_id, payload)
                    ok += 1

                except Exception as e:
                    fail += 1
                    st.warning(f"{i+1}í–‰ ì‹¤íŒ¨(ID={legacy_id}): {e}")

                prog.progress((i + 1) / len(df_csv))

        st.success(f"âœ… ë¦¬ìŠ¤íŠ¸ ì´ì „ ì™„ë£Œ: ì„±ê³µ {ok} / ìŠ¤í‚µ {skipped} / ì‹¤íŒ¨ {fail}")
        st.rerun()
